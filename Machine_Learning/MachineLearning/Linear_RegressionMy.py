####################### ####
# Sales Prediction with Linear Regression
####################### ####
# About how many sales were generated by ad spend

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

pd.set_option('display.float_format', lambda x: '%.2f' % x)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.model_selection import train_test_split, cross_val_score

####################### ####
# Simple Linear Regression with OLS Using Scikit-Learn
####################### ####

df = pd.read_csv("Machine_Learning/datasets/advertising.csv")
df.shape

# Let's take two variables
X = df[["TV"]] #argument
y = df[["sales"]] #dependent variable

#############################
# Model Setup
#############################

reg_model = LinearRegression().fit(X, y)

# y_hat = b + w*TV

# constant (b - bias)
reg_model.intercept_[0]

# coefficient of tv (w1)
reg_model.coef_[0][0]


#############################
# Guess
#############################

# How much sales are expected if there is a TV expenditure of 150 units?

reg_model.intercept_[0] + reg_model.coef_[0][0]*150

# How much sales would there be if there was a TV expenditure of 500 units?

reg_model.intercept_[0] + reg_model.coef_[0][0]*500

df.describe().T


# Visualization of the Model
# This is how the two-dimensional, two-variable model is represented:
g = sns.regplot(x=X, y=y, scatter_kws={'color': 'b', 's': 9},
                 ci=False, color="r")

g.set_title(f"Model Equation: Sales = {round(reg_model.intercept_[0], 2)} + TV*{round(reg_model.coef_[0][0], 2)}")
g.set_ylabel("Number of Sales")
g.set_xlabel("TV Expenses")
plt.xlim(-10, 310)
plt.ylim(bottom=0)
plt.show()


#############################
# Prediction Success
#############################

#MSE
y_pred = reg_model.predict(X)
mean_squared_error(y, y_pred)
#10.51 Average error

y.mean()
y.std()

#RMSE
np.sqrt(mean_squared_error(y, y_pred))
#3.24 An average error metric

#MAE
mean_absolute_error(y, y_pred)
#2.54 Absolute error

#R-SQUARE
reg_model.score(X, y)
# It is a very effective value for model success.
# This value is the percentage of independent variables in the data set that explain the dependent variable.
# In this model, the independent variable (Tv) can explain 61% of the dependent variables (Sales).

# As the number of variables increases, the r sqrt value tends to inflate. The corrected r sqrt value should also be taken into consideration here.
# We do not look at the issue from the perspective of statistical, economic and econometric values. Therefore, we are not interested in the meaningfulness of these models.


####################### ####
# Multiple Linear Regression
####################### ####
# Establishing multiple linear regression with multiple variables

df = pd.read_csv("Machine_Learning/datasets/advertising.csv")

# To get other variables (there are independent variables inside)
X = df.drop('sales', axis=1)

# To select dependent variable
y = df[["sales"]]


#############################
#Model
#############################
# We first separate the data set

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)

y_test.shape
y_train.shape

# Model setup
reg_model = LinearRegression().fit(X_train, y_train)

# to bring constant (b - bias)
reg_model.intercept_

# coefficients (w - weights) To get coefficients
reg_model.coef_


#############################
# Guess
#############################

# What is the expected value of the sale based on the following observation values?

# TV: 30
# radio: 10
#newspaper: 40

#2.90
#0.0468431, 0.17854434, 0.00258619

# Sales = 2.90 + TV * 0.04 + radio * 0.17 + newspaper * 0.002

2.90794702 + 30 * 0.0468431 + 10 * 0.17854434 + 40 * 0.00258619

# Let's express it in a functional way to transfer it to the relevant department
new_data = [[30], [10], [40]]

#Let's convert the data into dataframe
new_data = pd.DataFrame(new_data).T

# Prediction Success
reg_model.predict(new_data)

#############################
# Evaluating Prediction Success
#############################

# Train RMSE Error
y_pred = reg_model.predict(X_train)
np.sqrt(mean_squared_error(y_train, y_pred))
#1.73

# TRAIN SQUARE
reg_model.score(X_train, y_train)

# We approached 90 with 3 new variables. Our explanation rate increased with the new variable.

# Test RMSE
y_pred = reg_model.predict(X_test)
np.sqrt(mean_squared_error(y_test, y_pred))
#1.41
# As a relationship between train error and test, normally test error is higher.

# Test RQQ
reg_model.score(X_test, y_test)


# 10-Fold CV RMSE (All data used) Cross-validation
np.mean(np.sqrt(-cross_val_score(reg_model,
                                  x,
                                  y,
                                  cv=10,
                                  scoring="neg_mean_squared_error")))

#1.69
# Since our data set is small in size, this method may be more reliable.

#5 Layer CV RMSE
np.mean(np.sqrt(-cross_val_score(reg_model,
                                  x,
                                  y,
                                  cv=5,
                                  scoring="neg_mean_squared_error")))
#1.71



####################### ####
# Simple Linear Regression with Gradient Descent from Scratch
####################### ####

# Cost function MSE
def cost_function(Y, b, w, X):
     m = length(Y)
     sse = 0

     for i in range(0, m):
         y_hat = b + w * X[i]
         y = Y[i]
         sse += (y_hat - y) ** 2

     mse = sse/m
     return mse


# update_weights
def update_weights(Y, b, w, X, learning_rate):
     m = length(Y)
     b_deriv_sum = 0
     w_deriv_sum = 0
     for i in range(0, m):
         y_hat = b + w * X[i]
         y = Y[i]
         b_deriv_sum += (y_hat - y)
         w_deriv_sum += (y_hat - y) * X[i]
     new_b = b - (learning_rate * 1 / m * b_deriv_sum)
     new_w = w - (learning_rate * 1 / m * w_deriv_sum)
     return new_b, new_w


# train function
def train(Y, initial_b, initial_w, X, learning_rate, num_iters):

     print("Starting gradient descent at b = {0}, w = {1}, mse = {2}".format(initial_b, initial_w,
                                                                    cost_function(Y, initial_b, initial_w, X)))

     b = initial_b
     w = initial_w
     cost_history = []

     for i in range(num_iters):
         b, w = update_weights(Y, b, w, X, learning_rate)
         mse = cost_function(Y, b, w, X)
         cost_history.append(mse)


         if i % 100 == 0:
             print("iter={:d} b={:.2f} w={:.4f} mse={:.4}".format(i, b, w, mse))


     print("After {0} iterations b = {1}, w = {2}, mse = {3}".format(num_iters, b, w, cost_function(Y, b, w, X)))
     return cost_history, b, w


df = pd.read_csv("Machine_Learning/datasets/advertising.csv")

X = df["radio"]
Y = df["sales"]

# hyperparameters
learning_rate = 0.001
initial_b = 0.001
initial_w = 0.001
num_iters = 10000

cost_history, b, w = train(Y, initial_b, initial_w, X, learning_rate, num_iters)







